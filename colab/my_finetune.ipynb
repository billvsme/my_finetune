{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-50AbTRLCh5D"
      },
      "outputs": [],
      "source": [
        "\"\"\"ä¸‹è½½ä»£ç \n",
        "\"\"\"\n",
        "%cd /content/\n",
        "!git clone https://github.com/billvsme/my_finetune"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"ä¸‹è½½chatglm3-baseæ¨¡å‹, æ—¶é—´è¾ƒé•¿è¯·è€å¿ƒç­‰å¾…\n",
        "\"\"\"\n",
        "%cd /content/\n",
        "!git clone --depth=1 https://huggingface.co/THUDM/chatglm3-6b-base"
      ],
      "metadata": {
        "id": "vtbxBPhlC60S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"å®‰è£…ç¯å¢ƒ\n",
        "\"\"\"\n",
        "%cd /content/my_finetune\n",
        "\n",
        "!apt install -r python3.10-venv\n",
        "!mkdir ~/.venv\n",
        "!python -m venv ~/.venv/finetune\n",
        "!~/.venv/finetune/bin/pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "33opJSj6DVYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"æ›¿æ¢è‡ªæˆ‘è®¤çŸ¥self_cognitionæ•°æ®é›†ä¸­çš„åç§°\n",
        "\"\"\"\n",
        "%cd /content/my_finetune\n",
        "!sed -i 's/<NAME>/æ³•å¾‹AI/g' data/self_cognition.json\n",
        "!sed -i 's/<AUTHOR>/billvsme/g' data/self_cognition.json"
      ],
      "metadata": {
        "id": "WEUfm5T4tQoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"ç”Ÿæˆdeepspeedé…ç½®æ–‡ä»¶\n",
        "\"\"\"\n",
        "%cd /content/my_finetune\n",
        "!echo '''{\\\n",
        "  \"train_batch_size\": \"auto\",\\\n",
        "  \"train_micro_batch_size_per_gpu\": \"auto\",\\\n",
        "  \"gradient_accumulation_steps\": \"auto\",\\\n",
        "  \"gradient_clipping\": \"auto\",\\\n",
        "  \"zero_allow_untested_optimizer\": true,\\\n",
        "  \"fp16\": {\\\n",
        "    \"enabled\": \"auto\",\\\n",
        "    \"loss_scale\": 0,\\\n",
        "    \"initial_scale_power\": 16,\\\n",
        "    \"loss_scale_window\": 1000,\\\n",
        "    \"hysteresis\": 2,\\\n",
        "    \"min_loss_scale\": 1\\\n",
        "  },\\\n",
        "  \"zero_optimization\": {\\\n",
        "    \"stage\": 2,\\\n",
        "    \"allgather_partitions\": true,\\\n",
        "    \"allgather_bucket_size\": 1e8,\\\n",
        "    \"reduce_scatter\": true,\\\n",
        "    \"reduce_bucket_size\": 1e8,\\\n",
        "    \"overlap_comm\": true,\\\n",
        "    \"contiguous_gradients\": true\\\n",
        "  }\\\n",
        "}''' > ds_config.json"
      ],
      "metadata": {
        "id": "Xh5fnHg8tDTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"è¿›è¡Œqlora sftå¾®è°ƒ ğŸ¤©\n",
        "\"\"\"\n",
        "%cd /content/my_finetune\n",
        "!~/.venv/finetune/bin/deepspeed --num_gpus 1 --master_port=9901 finetune.py \\\n",
        "    --deepspeed ds_config.json \\\n",
        "    --model_name_or_path /content/chatglm3-6b-base \\\n",
        "    --do_train True\\\n",
        "    --data_dir /content/my_finetune/data/ \\\n",
        "    --data_filename self_cognition.json  \\\n",
        "    --max_source_length 2048 \\\n",
        "    --max_target_length 2048 \\\n",
        "    --max_samples 80 \\\n",
        "    --quantization_bit 4 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --lr_scheduler_type linear \\\n",
        "    --max_grad_norm 0.5 \\\n",
        "    --adam_beta1 0.9 \\\n",
        "    --adam_beta2 0.999 \\\n",
        "    --adam_epsilon 1e-8 \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.1 \\\n",
        "    --preprocessing_num_workers 4 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --max_steps 100 \\\n",
        "    --logging_steps 1 \\\n",
        "    --save_steps 1000 \\\n",
        "    --output_dir output/chatglmt3_qlora \\\n",
        "    --overwrite_output_dir True \\\n",
        "    --fp16 True"
      ],
      "metadata": {
        "id": "v_Te1LugrtxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"æŸ¥çœ‹å¾®è°ƒç»“æœğŸ˜\n",
        "\"\"\"\n",
        "%cd /content/my_finetune\n",
        "!~/.venv/finetune/bin/python inference.py \\\n",
        "    --model_name_or_path /content/chatglm3-6b-base \\\n",
        "    --lora_path output/chatglmt3_qlora \\\n",
        "    --data_dir /content/my_finetune/data/ \\\n",
        "    --data_filename self_cognition.json\\\n",
        "    --max_samples 80 \\\n",
        "    --quantization_bit 4\n"
      ],
      "metadata": {
        "id": "NKGQRhxkDddZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
